{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model, with trainable variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linear_mixed_effects_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-41ce3d260af8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_template\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_mixed_effects_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'linear_mixed_effects_model' is not defined"
     ]
    }
   ],
   "source": [
    "def linear_mixed_effects_model(features):\n",
    "  # Set up fixed effects and other parameters.\n",
    "  # Note: these are trainable!\n",
    "  intercept = tf.get_variable(\"intercept\", [])  # alpha in eq\n",
    "  effect_service = tf.get_variable(\"effect_service\", [])  # beta in eq\n",
    "  stddev_students = tf.exp(\n",
    "      tf.get_variable(\"stddev_unconstrained_students\", []))  # sigma in eq\n",
    "  stddev_instructors = tf.exp(\n",
    "      tf.get_variable(\"stddev_unconstrained_instructors\", [])) # sigma in eq\n",
    "  stddev_departments = tf.exp(\n",
    "      tf.get_variable(\"stddev_unconstrained_departments\", [])) # sigma in eq\n",
    "\n",
    "  # Set up random effects.\n",
    "  effect_students = ed.MultivariateNormalDiag(\n",
    "      loc=tf.zeros(num_students),\n",
    "      scale_identity_multiplier=stddev_students,\n",
    "      name=\"effect_students\")\n",
    "  effect_instructors = ed.MultivariateNormalDiag(\n",
    "      loc=tf.zeros(num_instructors),\n",
    "      scale_identity_multiplier=stddev_instructors,\n",
    "      name=\"effect_instructors\")\n",
    "  effect_departments = ed.MultivariateNormalDiag(\n",
    "      loc=tf.zeros(num_departments),\n",
    "      scale_identity_multiplier=stddev_departments,\n",
    "      name=\"effect_departments\")\n",
    "\n",
    "  # Set up likelihood given fixed and random effects.\n",
    "  # Note we use `tf.gather` instead of matrix-multiplying a design matrix of\n",
    "  # one-hot vectors. The latter is memory-intensive if there are many groups.\n",
    "  ratings = ed.Normal(\n",
    "      loc=(effect_service * features[\"service\"] +\n",
    "           tf.gather(effect_students, features[\"students\"]) +\n",
    "           tf.gather(effect_instructors, features[\"instructors\"]) +\n",
    "           tf.gather(effect_departments, features[\"departments\"]) +\n",
    "           intercept),\n",
    "      scale=1.,\n",
    "      name=\"ratings\")\n",
    "  return ratings\n",
    "\n",
    "model_template = tf.make_template(\"model\", linear_mixed_effects_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training operations\n",
    "* a \"loss minimization\" step\n",
    "* but since this is bayesian, also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define operations for sampling random effect values\n",
    "# samples are chosen that optimize the joint probability of y, X, and the effect values\n",
    "\n",
    "next_state, kernel_results = hmc.one_step(\n",
    "      current_state=current_state,\n",
    "      previous_kernel_results=hmc.bootstrap_results(current_state))\n",
    "\n",
    "\n",
    "current_state = ?\n",
    "\n",
    "next_state, kernel_results = hmc.one_step(\n",
    "    current_state=current_state,\n",
    "    \n",
    ")\n",
    "\n",
    "# kernel_results... used for what?\n",
    "# next_state is used for updating effect values, when sampled\n",
    "\n",
    "expectation_update = tf.group(  # tf.group - Create an op that groups multiple operations\n",
    "    effect_students.assign(next_state[0]),  # \n",
    "    effect_instructors.assign(next_state[1]),\n",
    "    effect_departments.assign(next_state[2]),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'effect_students' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1e017ff7e954>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m expectation_update = tf.group(  # tf.group - Create an op that groups multiple operations\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0meffect_students\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0meffect_instructors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0meffect_departments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'effect_students' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "define bayesian fitting steps:\n",
    "  * minimization_update: update trainable variables\n",
    "    * it minimizes the joint log likelihood function of X, y, and parameter values\n",
    "    * this depends on the distributions learned for the parameter values, which vary by effect means\n",
    "  * expectation_update: update group effects\n",
    "    * this is a monte carlo sampling operation\n",
    "'''\n",
    "\n",
    "# define the minimization step\n",
    "# this improves fits of fixed effects, given the random effects\n",
    "# this with block makes sure that random effects are updated before any of these operations\n",
    "with tf.control_dependencies([expectation_update]):\n",
    "    # tf.control_dependencies - adds dependencies to ops you create in the with block\n",
    "    # `loss` = negative log of probability, given group effects\n",
    "    loss = -target_log_prob_fn(\n",
    "        effect_students,\n",
    "        effect_instructors,\n",
    "        effect_departments)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "    # minimize according to effects passed to loss\n",
    "    minimization_update = optimizer.minimize(loss)\n",
    "\n",
    "'''\n",
    "operations defined here...\n",
    "expectation_update -> loss -> minimization_update\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expectation_update = tf.group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_students = max(features_train['students']) + 1\n",
    "num_instructors = max(features_train['instructors']) + 1\n",
    "num_departments = max(features_train['departments']) + 1\n",
    "num_observations = train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "num_warmup_iters = 1000\n",
    "num_iters = 1500\n",
    "num_accepted = 0\n",
    "effect_students_samples = np.zeros([num_iters, num_students])\n",
    "effect_instructors_samples = np.zeros([num_iters, num_instructors])\n",
    "effect_departments_samples = np.zeros([num_iters, num_departments])\n",
    "loss_history = np.zeros([num_iters])\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Fetch argument None has invalid type <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-447e77ddb0df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# run 5 MCMC iterations before every joint EM update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpectation_update\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   [\n\u001b[1;32m      6\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1095\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \"\"\"\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m       raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n\u001b[0;32m--> 244\u001b[0;31m                                                                  type(fetch)))\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m       \u001b[0;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Fetch argument None has invalid type <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "# Run training.\n",
    "for t in range(num_iters):\n",
    "  for _ in range(5):  # run 5 MCMC iterations before every joint EM update\n",
    "    _ = sess.run(expectation_update)\n",
    "  [\n",
    "      _,\n",
    "      _,\n",
    "      effect_students_val,\n",
    "      effect_instructors_val,\n",
    "      effect_departments_val,\n",
    "      is_accepted_val,\n",
    "      loss_val,\n",
    "  ] = sess.run([\n",
    "      expectation_update,\n",
    "      minimization_update,\n",
    "      effect_students,\n",
    "      effect_instructors,\n",
    "      effect_departments,\n",
    "      kernel_results.is_accepted,\n",
    "      loss,\n",
    "  ])\n",
    "  effect_students_samples[t, :] = effect_students_val\n",
    "  effect_instructors_samples[t, :] = effect_instructors_val\n",
    "  effect_departments_samples[t, :] = effect_departments_val\n",
    "  num_accepted += is_accepted_val\n",
    "  loss_history[t] = loss_val\n",
    "  if t % 500 == 0 or t == num_iters - 1:\n",
    "    print(\"Iteration: {:>4} Acceptance Rate: {:.3f} Loss: {:.3f}\".format(\n",
    "        t, num_accepted / (t + 1), loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
